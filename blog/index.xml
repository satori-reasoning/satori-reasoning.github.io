<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Blog on Satori</title>
    <link>http://localhost:1313/blog/</link>
    <description>Recent content in Blog on Satori</description>
    <image>
      <url>http://localhost:1313/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E</url>
      <link>http://localhost:1313/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E</link>
    </image>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Sat, 01 Feb 2025 12:00:00 +0800</lastBuildDate><atom:link href="http://localhost:1313/blog/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Satori: Reinforcement Learning with Chain-of-Action-Thought Enhances LLM Reasoning via Autoregressive Search</title>
      <link>http://localhost:1313/blog/satori/</link>
      <pubDate>Sat, 01 Feb 2025 12:00:00 +0800</pubDate>
      
      <guid>http://localhost:1313/blog/satori/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;&#34; class=&#34;btn external&#34; target=&#34;_blank&#34;&gt;Paper&lt;/a&gt;
&lt;a href=&#34;https://github.com/satori-reasoning/Satori&#34; class=&#34;btn external&#34; target=&#34;_blank&#34;&gt;Github&lt;/a&gt;
&lt;a href=&#34;https://huggingface.co/Satori-reasoning&#34; class=&#34;btn external&#34; target=&#34;_blank&#34;&gt;Huggingface&lt;/a&gt;&lt;/p&gt;
&lt;style&gt;
.code-box {
    max-height: 350px;
    overflow-y: auto;
    padding: 10px;
    background-color: #f8f8f8; 
    font-family: &#39;Menlo&#39;, Consolas, Monaco, &#39;Courier New&#39;, monospace;
    font-size: 14px;
    line-height: 1.5;
    white-space: pre-wrap;
    word-wrap: break-word;
    border-radius: 5px; 
}

.code-box b {
    font-weight: 600 !important; /* Force stronger boldness */
    color: #111111; /* Change text color to something more vibrant */
}

.code-box b, .code-box strong {
    font-weight: bold !important;
}

&lt;/style&gt;
&lt;h2 id=&#34;introduction&#34;&gt;&lt;strong&gt;Introduction&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;Since the release of OpenAI&#39;s o1, significant efforts have been made within the research community to enhance open-source LLMs with advanced reasoning capabilities. This includes various approaches, including distillation using a strong teacher model, MCTS, and reward model guided search. This work aims to explore a new research direction: enabling LLMs with autoregressive search capabilities, i.e., a single LLM performs an extended reasoning process with self-reflection and self-exploration of new strategies. To achieve this, we develop a LLM post-training paradigm with several key concepts and ideas inspired by classical reinforcement learning (RL) communities. Our approach results in Satori, a 7B LLM trained on open-source model (Qwen-2.5-Math-7B) and open-source data (OpenMathInstruct-2 and NuminaMath). Key features of Satori include:&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>
