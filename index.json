[{"summary":"\u003cp\u003e\u003ca href=\"\" class=\"btn external\" target=\"_blank\"\u003ePaper\u003c/a\u003e\n\u003ca href=\"https://github.com/satori-reasoning/Satori-SWE\" class=\"btn external\" target=\"_blank\"\u003eGithub\u003c/a\u003e\n\u003ca href=\"https://huggingface.co/Satori-reasoning\" class=\"btn external\" target=\"_blank\"\u003eHuggingface\u003c/a\u003e\u003c/p\u003e\n\u003cstyle\u003e\n.code-box {\n    max-height: 350px;\n    overflow-y: auto;\n    padding: 10px;\n    font-family: 'Menlo', Consolas, Monaco, 'Courier New', monospace;\n    font-size: 18px;\n    line-height: 1.5;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    border-radius: 5px; \n}\n\n.issue-box {\n    max-height: 350px;\n    overflow-y: auto;\n    padding: 10px;\n    background-color: #f8f8f8; \n    font-family: 'Menlo', Consolas, Monaco, 'Courier New', monospace;\n    font-size: 14px;\n    line-height: 1.5;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    border-radius: 5px; \n}\n\n.correct_patch {\n    background-color:rgb(207, 248, 206); \n}\n\n.code-box b {\n    font-weight: 600 !important; /* Force stronger boldness */\n    color: #111111; /* Change text color to something more vibrant */\n}\n\n.code-box b, .code-box strong {\n    font-weight: bold !important;\n}\n\n\u003c/style\u003e\n\u003ch2 id=\"introduction\"\u003e\u003cstrong\u003eIntroduction\u003c/strong\u003e\u003c/h2\u003e\n\u003cp\u003eLLMs perform well on coding benchmarks like LiveCodeBench but struggle with real-world software engineering (SWE) tasks (\u003ca href=\"https://openreview.net/pdf?id=VTF8yNQM66\"\u003eJimenez et al. 2024\u003c/a\u003e). Even large models like Claude reach only around 60% accuracy on SWE-bench, despite using carefully engineered prompting pipelines (\u003ca href=\"https://arxiv.org/pdf/2407.01489\"\u003eXia et al. 2024\u003c/a\u003e). Smaller models (under 100B parameters) perform significantly worse, typically scoring below 10% in zero-shot settings and plateauing around 30% after supervised fine-tuning (SFT) (\u003ca href=\"https://arxiv.org/pdf/2412.21139\"\u003ePan et al. 2024\u003c/a\u003e, \u003ca href=\"https://arxiv.org/pdf/2501.05040\"\u003eXie et al. 2025\u003c/a\u003e) on GitHub issue datasets. Improving the performance of these small models remains a key challenge for practical deployment, where repeatedly querying large models is often too costly or inefficient.\u003c/p\u003e","title":"Satori-SWE: Evolutionary Test-Time Scaling for Sample-Efficient Software Engineering"},{"summary":"\u003cp\u003e\u003ca href=\"https://arxiv.org/pdf/2502.02508\" class=\"btn external\" target=\"_blank\"\u003ePaper\u003c/a\u003e\n\u003ca href=\"https://github.com/satori-reasoning/Satori\" class=\"btn external\" target=\"_blank\"\u003eGithub\u003c/a\u003e\n\u003ca href=\"https://huggingface.co/Satori-reasoning\" class=\"btn external\" target=\"_blank\"\u003eHuggingface\u003c/a\u003e\u003c/p\u003e\n\u003cstyle\u003e\n.code-box {\n    max-height: 350px;\n    overflow-y: auto;\n    padding: 10px;\n    background-color: #f8f8f8; \n    font-family: 'Menlo', Consolas, Monaco, 'Courier New', monospace;\n    font-size: 14px;\n    line-height: 1.5;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    border-radius: 5px; \n}\n\n.code-box b {\n    font-weight: 600 !important; /* Force stronger boldness */\n    color: #111111; /* Change text color to something more vibrant */\n}\n\n.code-box b, .code-box strong {\n    font-weight: bold !important;\n}\n\n\u003c/style\u003e\n\u003ch2 id=\"introduction\"\u003e\u003cstrong\u003eIntroduction\u003c/strong\u003e\u003c/h2\u003e\n\u003cp\u003eSince the release of OpenAI's o1, significant efforts have been made within the research community to enhance open-source LLMs with advanced reasoning capabilities. This includes various approaches, including distillation using a strong teacher model, MCTS, and reward model guided search. This work aims to explore a new research direction: enabling LLMs with autoregressive search capabilities, i.e., a single LLM performs an extended reasoning process with self-reflection and self-exploration of new strategies. To achieve this, we develop a LLM post-training paradigm with several key concepts and ideas inspired by classical reinforcement learning (RL) communities. Our approach results in Satori, a 7B LLM trained on open-source model (Qwen-2.5-Math-7B) and open-source data (OpenMathInstruct-2 and NuminaMath). Key features of Satori include:\u003c/p\u003e","title":"Satori: Reinforcement Learning with Chain-of-Action-Thought Enhances LLM Reasoning via Autoregressive Search"}]